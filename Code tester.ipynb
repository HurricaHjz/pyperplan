{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8934fa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "from scipy import stats\n",
    "import copy\n",
    "import os\n",
    "\n",
    "from pyperplan import planner as pl\n",
    "from pyperplan.planner import (\n",
    "    find_domain,\n",
    "    HEURISTICS,\n",
    "    search_plan,\n",
    "    SEARCHES,\n",
    "    validate_solution,\n",
    "    write_solution,\n",
    ")\n",
    "from pyperplan.task import Operator, Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5951b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the planning graph\n",
    "class RelaxedGraph(object):\n",
    "    \n",
    "    def __init__(self): # initialise the Graph\n",
    "        self.num_of_levels: int = 0\n",
    "        self.act = {0: None}\n",
    "        self.prop = {}\n",
    "        self.fixed_point = False\n",
    "        \n",
    "            \n",
    "\n",
    "class RelaxedPlanningGraph(object):\n",
    "    \n",
    "    def __init__(self, domain_file: str, problem_file: str):\n",
    "        # initialise the relaxed planning graph\n",
    "        self.task = pl._ground(pl._parse(domain_file, problem_file))\n",
    "        self.graph = RelaxedGraph()\n",
    "        self.plan = None\n",
    "        self.hff = -1 # not yet generated\n",
    "        self.dom = domain_file\n",
    "        self.prob = problem_file\n",
    "        \n",
    "    def create(self, max_depth, state = None):\n",
    "        # create the planning graph with a initial state specified\n",
    "        # return the level of relaxed graph generated, -1 if reached fixed point, -2 if reached max depth\n",
    "        self.graph = RelaxedGraph()\n",
    "        if state is not None:\n",
    "            self.graph.prop = {0: set(state)}\n",
    "        else:\n",
    "            self.graph.prop = {0: set(self.task.initial_state)}\n",
    "        goal_set = self.task.goals\n",
    " \n",
    "        for level in range(max_depth+1):\n",
    "            current_props = self.graph.prop[level]\n",
    "            # if the goal has been satisfied\n",
    "            if Task.goal_reached(self.task, current_props):\n",
    "                return level\n",
    "            \n",
    "            # else expand the relaxed graph\n",
    "            self.graph.act[level+1] = set([op for op in self.task.operators if op.applicable(current_props)])\n",
    "            \n",
    "            next_props = current_props.copy()\n",
    "            for op in self.graph.act[level+1]:\n",
    "                next_props = next_props | op.add_effects\n",
    "            \n",
    "            if len(current_props) == len(next_props):\n",
    "                return -1 # reached fixed point before finding the goal\n",
    "            self.graph.prop[level+1] = next_props\n",
    "        \n",
    "        return -2 #reached max depth\n",
    "        \n",
    "#     def plan(self):\n",
    "#             currently using the default planning, modify later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c620cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpl = RelaxedPlanningGraph(\"benchmarks/blocks/domain.pddl\",\"benchmarks/blocks/task01.pddl\")\n",
    "\n",
    "rpl.create(999)\n",
    "\n",
    "graph = rpl.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ecbcab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = np.array([1,2,3,4])\n",
    "counter = np.zeros(4)\n",
    "counter[l == 3]+=1\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d5d0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_vec_relaxed(planning_graph, state, max_level):\n",
    "    \"\"\"\n",
    "    Generate the feature vector followed by the paper from the input (problem, state) pair as described by the paper\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    planning_graph: the relaxed planning graph DAG pi\n",
    "    state: the current state s\n",
    "    max_level: the maximum layer allowed for ff algorithm to do forward expanding\n",
    "    \n",
    "    Outputs\n",
    "    ----------\n",
    "    feature_vec: a vector of length n + 2*n**2 + 3 representing the feature generated from the given (problem, state) pair\n",
    "                 the first n values are single action feature\n",
    "                 the second 2*n**2 are pairwise action feature\n",
    "                 the last 3 are original heuristic value, the number of layers in pi and the number of unsatisfied goals\n",
    "    \"\"\"\n",
    "    # get the graph\n",
    "    graph = planning_graph.graph.copy()\n",
    "    # get action schema and output list\n",
    "    act_schema = np.array(list(set(planning_graph.task.operators().name))) # store names of total action schema\n",
    "    n = len(act_schema)  # length of action schema\n",
    "    feature_vec = np.zeros(n+2*n**2+3) # return feature vec, first n is linear, second 2*n**2 is pairwise, last 3 is additional feature\n",
    "    act_layers = list(graph.act.values()) # list of layers generated, ith value is the list of actions connencting i-1 th states to ith states layer\n",
    "\n",
    "    # extract linear feature\n",
    "    #-------------------------------------\n",
    "    # ith value indicate the num of occurance for ith action of act_schema in the entire graph \n",
    "    counter = np.zeros(n)\n",
    "    for act_layer in act_layers:\n",
    "        if act_layer is not None:\n",
    "            for a in act_layer:\n",
    "                counter[act_schema == a.name] += 1 \n",
    "    feature_vec[0:n] = counter\n",
    "    \n",
    "    # extract pair-wise feature\n",
    "    #-------------------------------------\n",
    "    # each pair a1, a2 is stored in n + [2*(n*a1+a2), 2*(n*a1+a2)+1]\n",
    "    # e.g. when a1 is 1, a2 is 3, n is 5, store in 5 + [2*(8),  2*(8)+1]\n",
    "    def to_index(n, index_a1, index_a2, adder):\n",
    "        \"\"\"\n",
    "        return corresponding index in the position of the feature vector\n",
    "        adder is either 0 or 1\n",
    "        index_a1, index_a2 refer to move index in act_schema\n",
    "        \"\"\"\n",
    "        return n+2*(n*index_a1+index_a2)+adder\n",
    "    \n",
    "    \n",
    "    def append_to_dict(a, pre, eff_pos):\n",
    "        \"\"\"\n",
    "        add action a into the dicitonary pre and eff_pos\n",
    "        \"\"\"\n",
    "        for p in a.precondition_pos:\n",
    "            current = pre.get(p)\n",
    "            if current is None:\n",
    "                current = [a]\n",
    "            else:\n",
    "                current.append(a)\n",
    "            pre[p] = current\n",
    "            \n",
    "        for p in a.effect_pos:\n",
    "            current = eff_pos.get(p)\n",
    "            if current is None:\n",
    "                current = [a]\n",
    "            else:\n",
    "                current.append(a)\n",
    "            eff_pos[p] = current\n",
    "            \n",
    "            return pre, eff_pos\n",
    "\n",
    "\n",
    "    # define dictionary variables for comparison purpose\n",
    "    pre = {}\n",
    "    eff_pos = {}\n",
    "    \n",
    "    # add pre and eff into the empty dictionary for the first layer\n",
    "    for a in act_layers[1]:\n",
    "        if not isinstance(a, NoOpAction):\n",
    "            pre, eff_pos = append_to_dict(a, pre, eff_pos)\n",
    "   \n",
    "    # loop through second to last action layers\n",
    "    for i in range(2,len(act_layers)): \n",
    "        act_layer = act_layers[i]\n",
    "        \n",
    "        # update fecture vec for the entire layer\n",
    "        for a2 in act_layer:\n",
    "            if not isinstance(a2, NoOpAction):\n",
    "                # count for num of occurances, use set to avoid multiple countsc\n",
    "                s1 = set() # feature 1 where eff a1 and pre a2 has intersections\n",
    "                s2 = set() # feature 2 where pre a1 and eff a2 has intersections          \n",
    "                for p in a2.precondition_pos:\n",
    "                    current = eff_pos.get(p)\n",
    "                    if current is not None:\n",
    "                        for a1 in current:\n",
    "                            s1.add(a1) \n",
    "\n",
    "                for p in a2.effect_pos:\n",
    "                    current = pre.get(p)\n",
    "                    if current is not None:\n",
    "                        for a1 in current:\n",
    "                            s2.add(a1)\n",
    "                            \n",
    "                # add index to feature_vec based on set generated:\n",
    "                index_a2 = int(np.where(a2.operator_name == act_schema)[0])\n",
    "                for a1 in s1:\n",
    "                    # update feature 1 for pair (a1, a2)\n",
    "                    index_a1 = int(np.where(a1.operator_name == act_schema)[0])\n",
    "                    feature_vec[to_index(n, index_a1, index_a2,0)]+=1\n",
    "      \n",
    "                for a1 in s2:\n",
    "                    # update feature 2 for pair (a1, a2)\n",
    "                    index_a1 = int(np.where(a1.operator_name == act_schema)[0])\n",
    "                    feature_vec[to_index(n, index_a1, index_a2,1)]+=1\n",
    "\n",
    "        # update pre and eff_pos for the entire layer\n",
    "        for a2 in act_layer:\n",
    "            if not isinstance(a2, NoOpAction):\n",
    "                pre, eff_pos = append_to_dict(a2, pre, eff_pos)\n",
    "           \n",
    "    # extract final features\n",
    "    #-------------------------------------\n",
    "    # add heuristic value, number of layers and number of unsatisfied goals\n",
    "    # number of layers:\n",
    "    feature_vec[total_len - 3] = len(act_layers)\n",
    "    # heuristic value hFF: (number of total actions in the plan)\n",
    "    feature_vec[total_len - 2] = planning_graph.hff\n",
    "    \n",
    "    ### ISSUE: UNSATISFIED GOAL FEATURE\n",
    "    #-------------------------------------\n",
    "#     # unsatisfied goal (2 ** (last layer total pos num - goal state pos num))\n",
    "#     last = graph.prop[len(graph.prop)-1]\n",
    "#     feature_vec[total_len - 1] = 2 ** (len(last) - len(goal))\n",
    "    #-------------------------------------\n",
    "    \n",
    "\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd671c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
