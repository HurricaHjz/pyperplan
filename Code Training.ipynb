{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8934fa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "from scipy import stats\n",
    "import copy\n",
    "import os\n",
    "\n",
    "from pyperplan import planner as pl\n",
    "from pyperplan.planner import (\n",
    "    find_domain,\n",
    "    HEURISTICS,\n",
    "    search_plan,\n",
    "    SEARCHES,\n",
    "    validate_solution,\n",
    "    write_solution,\n",
    ")\n",
    "from pyperplan.task import Operator, Task\n",
    "from typing import Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5951b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the planning graph\n",
    "class RelaxedGraph(object):\n",
    "    \n",
    "    def __init__(self): # initialise the Graph\n",
    "        self.num_of_levels: int = 0\n",
    "        self.act = {0: None}\n",
    "        self.prop = {}\n",
    "        self.fixed_point = False\n",
    "        \n",
    "            \n",
    "\n",
    "class RelaxedPlanningGraph(object):\n",
    "    \n",
    "    def __init__(self, domain_file: str, problem_file: str):\n",
    "        # initialise the relaxed planning graph\n",
    "        self.task = pl._ground(pl._parse(domain_file, problem_file))\n",
    "        self.graph = None\n",
    "        self.plan = None\n",
    "        self.hff = -1 # not yet generated\n",
    "        self.dom = domain_file\n",
    "        self.prob = problem_file\n",
    "        self.success = False # whether successfully generated or not\n",
    "        \n",
    "    def create(self, max_depth, state = None):\n",
    "        # create the planning graph with a initial state specified\n",
    "        # return the level of relaxed graph generated, -1 if reached fixed point, -2 if reached max depth\n",
    "        self.graph = RelaxedGraph()\n",
    "        if state is not None:\n",
    "            self.graph.prop = {0: set(state)}\n",
    "        else:\n",
    "            self.graph.prop = {0: set(self.task.initial_state)}\n",
    "        goal_set = self.task.goals\n",
    " \n",
    "        for level in range(max_depth+1):\n",
    "            current_props = self.graph.prop[level]\n",
    "            # if the goal has been satisfied\n",
    "            if Task.goal_reached(self.task, current_props):\n",
    "                self.success = True\n",
    "                return level\n",
    "            \n",
    "            # else expand the relaxed graph\n",
    "            self.graph.act[level+1] = set([op for op in self.task.operators if op.applicable(current_props)])\n",
    "            \n",
    "            next_props = current_props.copy()\n",
    "            for op in self.graph.act[level+1]:\n",
    "                next_props = next_props | op.add_effects\n",
    "            \n",
    "            if len(current_props) == len(next_props):\n",
    "                return -1 # reached fixed point before finding the goal\n",
    "            self.graph.prop[level+1] = next_props\n",
    "        \n",
    "        return -2 #reached max depth\n",
    "        \n",
    "    def hff_plan(self):\n",
    "        # generate a relaxed plan with hff \n",
    "        # first return error if graph not successfully generated\n",
    "        # return hff, -1 if failed\n",
    "        if self.graph is None:\n",
    "            print(\"Graph not yet generated\")\n",
    "            return -1 # graph not yet created\n",
    "        if not self.success:\n",
    "            print(\"Invalid graph\")\n",
    "            return -1 # graph does not reach goal state\n",
    "        \n",
    "        # otherwise start backtrace\n",
    "        # setup g_k\n",
    "        current_goal = set(self.task.goals.copy())\n",
    "        k = len(self.graph.act.keys())-1\n",
    "        self.plan = {}\n",
    "        for i in range(k, 0, -1):\n",
    "            act_set = set()\n",
    "            # select the minimum set of actions that r-satisfied current goal\n",
    "            for a in self.graph.act[i]:\n",
    "                for eff in a.add_effects:\n",
    "                    if eff in current_goal:\n",
    "                        current_goal.remove(eff)\n",
    "                        act_set.add(a)\n",
    "            # update the current goal to be the goals for previous layer\n",
    "            for a in act_set:\n",
    "                current_goal.update(a.preconditions)\n",
    "                \n",
    "            # update the final plan\n",
    "            self.plan[i] = list(act_set)\n",
    "\n",
    "        \n",
    "        if current_goal.issubset(self.graph.prop[0]):\n",
    "            count = 0\n",
    "            for layer in self.plan.values():\n",
    "                count+=len(layer)\n",
    "            self.hff = count\n",
    "            return self.hff\n",
    "        else:\n",
    "            print(\"something went wrong during planning\")\n",
    "            return -1\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c620cec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pick-up b)\n",
      "(pick-up a)\n",
      "(pick-up c)\n",
      "(pick-up d)\n",
      "(put-down b)\n",
      "(put-down a)\n",
      "(put-down c)\n",
      "(put-down d)\n",
      "(stack b b)\n",
      "(stack b a)\n",
      "(stack b c)\n",
      "(stack b d)\n",
      "(stack a b)\n",
      "(stack a a)\n",
      "(stack a c)\n",
      "(stack a d)\n",
      "(stack c b)\n",
      "(stack c a)\n",
      "(stack c c)\n",
      "(stack c d)\n",
      "(stack d b)\n",
      "(stack d a)\n",
      "(stack d c)\n",
      "(stack d d)\n",
      "(unstack b b)\n",
      "(unstack b a)\n",
      "(unstack b c)\n",
      "(unstack b d)\n",
      "(unstack a b)\n",
      "(unstack a a)\n",
      "(unstack a c)\n",
      "(unstack a d)\n",
      "(unstack c b)\n",
      "(unstack c a)\n",
      "(unstack c c)\n",
      "(unstack c d)\n",
      "(unstack d b)\n",
      "(unstack d a)\n",
      "(unstack d c)\n",
      "(unstack d d)\n"
     ]
    }
   ],
   "source": [
    "rpl = RelaxedPlanningGraph(\"benchmarks/blocks/domain.pddl\",\"benchmarks/blocks/task03.pddl\")\n",
    "\n",
    "rpl.create(999)\n",
    "\n",
    "graph = rpl.graph\n",
    "\n",
    "for o in rpl.task.operators:\n",
    "    print(o.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4ecbcab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "fs = frozenset([6, 7, 8, 9])\n",
    "s = {1, 2, 3, 4, 5}\n",
    "\n",
    "y = {1,2,6}\n",
    "\n",
    "print(s - y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0d5d0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_vec_relaxed(planning_graph, state, max_level):\n",
    "    \"\"\"\n",
    "    Generate the feature vector followed by the paper from the input (problem, state) pair as described by the paper\n",
    "    Please notice that action and operator are referring to the same type Operator within this function\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    planning_graph: the relaxed planning graph DAG pi\n",
    "    state: the current state s\n",
    "    max_level: the maximum layer allowed for ff algorithm to do forward expanding\n",
    "    \n",
    "    Outputs\n",
    "    ----------\n",
    "    feature_vec: a vector of length n + 2*n**2 + 3 representing the feature generated from the given (problem, state) pair\n",
    "                 the first n values are single action feature\n",
    "                 the second 2*n**2 are pairwise action feature\n",
    "                 the last 3 are original heuristic value, the number of layers in pi and the number of unsatisfied goals\n",
    "    \"\"\"\n",
    "    def get_name(op_name):\n",
    "        \"\"\"\n",
    "        transfer an operator name from format of \"(act_name v1 v2...)\" to act_name string\n",
    "        \"\"\"\n",
    "        return op_name.split(\" \")[0][1:]\n",
    "    \n",
    "    \n",
    "    # create and get the graph\n",
    "    planning_graph.create(max_level, state)\n",
    "    planning_graph.hff_plan()\n",
    "    graph = planning_graph.graph\n",
    "    # get action schema and output list\n",
    "    act_schema = np.array(list(set([get_name(o.name) for o in planning_graph.task.operators]))) # store names of total action schema\n",
    "    n = len(act_schema)  # length of action schema\n",
    "    total_len = n+2*n**2+3\n",
    "    feature_vec = np.zeros(total_len) # return feature vec, first n is linear, second 2*n**2 is pairwise, last 3 is additional feature\n",
    "    act_layers = list(graph.act.values()) # list of layers generated, ith value is the list of actions connencting i-1 th states to ith states layer\n",
    "    \n",
    "    # extract linear feature\n",
    "    #-------------------------------------\n",
    "    # ith value indicate the num of occurance for ith action of act_schema in the entire graph \n",
    "    counter = np.zeros(n)\n",
    "    for act_layer in act_layers:\n",
    "        if act_layer is not None:\n",
    "            for a in act_layer:\n",
    "                counter[act_schema == get_name(a.name)] += 1 \n",
    "    feature_vec[0:n] = counter\n",
    "    \n",
    "    # extract pair-wise feature\n",
    "    #-------------------------------------\n",
    "    # each pair a1, a2 is stored in n + [2*(n*a1+a2), 2*(n*a1+a2)+1]\n",
    "    # e.g. when a1 is 1, a2 is 3, n is 5, store in 5 + [2*(8),  2*(8)+1]\n",
    "    \n",
    "    def to_index(n, index_a1, index_a2, adder):\n",
    "        \"\"\"\n",
    "        return corresponding index in the position of the feature vector\n",
    "        adder is either 0 or 1\n",
    "        index_a1, index_a2 refer to move index in act_schema\n",
    "        \"\"\"\n",
    "        return n+2*(n*index_a1+index_a2)+adder\n",
    "    \n",
    "\n",
    "    def append_to_dict(a, pre, eff_pos):\n",
    "        \"\"\"\n",
    "        add action a into the dicitonary pre and eff_pos\n",
    "        \"\"\"\n",
    "        for p in a.preconditions:\n",
    "            current = pre.get(p)\n",
    "            if current is None:\n",
    "                current = [a]\n",
    "            else:\n",
    "                current.append(a)\n",
    "            pre[p] = current\n",
    "            \n",
    "        for p in a.add_effects:\n",
    "            current = eff_pos.get(p)\n",
    "            if current is None:\n",
    "                current = [a]\n",
    "            else:\n",
    "                current.append(a)\n",
    "            eff_pos[p] = current\n",
    "            \n",
    "            return pre, eff_pos\n",
    "\n",
    "\n",
    "    # define dictionary variables for comparison purpose\n",
    "    # each dictionary maps a fact(proposition) to a list of actions\n",
    "    pre = {}\n",
    "    eff_pos = {}\n",
    "    \n",
    "    # add pre and eff into the empty dictionary for the first layer\n",
    "    for a in act_layers[1]:\n",
    "        pre, eff_pos = append_to_dict(a, pre, eff_pos)\n",
    "   \n",
    "    # loop through second to last action layers\n",
    "    for i in range(2,len(act_layers)): \n",
    "        act_layer = act_layers[i]\n",
    "        \n",
    "        # update fecture vec for the entire layer based on all previously visited layers\n",
    "        for a2 in act_layer:\n",
    "            # count for num of occurances, use set to avoid multiple counts\n",
    "            s1 = set() # feature 1 where eff a1 and pre a2 has intersections\n",
    "            s2 = set() # feature 2 where pre a1 and eff a2 has intersections          \n",
    "            for p in a2.preconditions:\n",
    "                current = eff_pos.get(p)\n",
    "                if current is not None:\n",
    "                    for a1 in current:\n",
    "                        s1.add(a1) \n",
    "\n",
    "            for p in a2.add_effects:\n",
    "                current = pre.get(p)\n",
    "                if current is not None:\n",
    "                    for a1 in current:\n",
    "                        s2.add(a1)\n",
    "\n",
    "            # add index to feature_vec based on set generated:\n",
    "            index_a2 = int(np.where(get_name(a2.name) == act_schema)[0])\n",
    "            for a1 in s1:\n",
    "                # update feature 1 for pair (a1, a2)\n",
    "                index_a1 = int(np.where(get_name(a1.name) == act_schema)[0])\n",
    "                feature_vec[to_index(n, index_a1, index_a2,0)]+=1\n",
    "\n",
    "            for a1 in s2:\n",
    "                # update feature 2 for pair (a1, a2)\n",
    "                index_a1 = int(np.where(get_name(a1.name) == act_schema)[0])\n",
    "                feature_vec[to_index(n, index_a1, index_a2,1)]+=1\n",
    "\n",
    "        # update pre and eff_pos for the entire layer\n",
    "        for a2 in act_layer:\n",
    "            pre, eff_pos = append_to_dict(a2, pre, eff_pos)\n",
    "           \n",
    "    # extract final features\n",
    "    #-------------------------------------\n",
    "    # add heuristic value, number of layers and number of unsatisfied goals\n",
    "    # number of layers:\n",
    "    feature_vec[total_len - 3] = len(act_layers)\n",
    "    # heuristic value hFF: (number of total actions in the plan)\n",
    "    feature_vec[total_len - 2] = planning_graph.hff\n",
    "    \n",
    "    ### ISSUE: UNSATISFIED GOAL FEATURE\n",
    "    #-------------------------------------\n",
    "#     # unsatisfied goal (2 ** (last layer total pos num - goal state pos num))\n",
    "#     last = graph.prop[len(graph.prop)-1]\n",
    "#     feature_vec[total_len - 1] = 2 ** (len(last) - len(goal))\n",
    "    #-------------------------------------\n",
    "    \n",
    "\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fa4039bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_operator(action : str, ops):\n",
    "    \"\"\"\n",
    "    find an operator from the planning graph's ground operator lists\n",
    "    \n",
    "    return: the action operator if found\n",
    "    \"\"\"\n",
    "    for op in ops:\n",
    "        if op.name == action:\n",
    "            return op\n",
    "    return None\n",
    "\n",
    "\n",
    "def read_plan(plan_file_path: str):\n",
    "    \"\"\"\n",
    "    read all the lines from a plan file directory, remove the last line containing cost\n",
    "    \n",
    "    return: a list containing the ground truth plan with length equal to total cost\n",
    "    \"\"\"\n",
    "    with open(plan_file_path, \"r\") as f:\n",
    "\n",
    "        # Read the lines of the file into a list of strings\n",
    "        lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    return lines[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2fc68364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(domain_file_path, task_file_path, plan_file_path, problem_num : int):\n",
    "    \"\"\"\n",
    "    generate the feature vector matrix X together with a cost vector y from the given input\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    domain_file_path: the input domain file\n",
    "    task_file_path: the input problem file\n",
    "    plan_file_path: the input log file that store the optimal plan\n",
    "    problem_num: the problem index for this domain\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    None, None if no plan can be found (plan has cost 0)\n",
    "    X : array, shape (plan_length-1, n_features)\n",
    "        The input feature vec of states from initial states all the way towards the second-last state (one state before goal state)\n",
    "    Y : array, shape (plan_length-1, 2)\n",
    "        The input cost vector. If it's a 2D array\n",
    "        The first column is the true cost pi optimal (assume unit cost)\n",
    "        The second column is the probelm_num representing the index of this problem\n",
    "    \n",
    "    \"\"\"\n",
    "    # generate plan and get max level\n",
    "    plan_actions = read_plan(plan_file_path)\n",
    "    if len(plan_actions) == 0:\n",
    "        return None, None\n",
    "    max_level = len(plan_actions)+2\n",
    "    \n",
    "    # generate relaxed planning graph\n",
    "    planning_graph = RelaxedPlanningGraph(domain_file_path, task_file_path)\n",
    "    \n",
    "    # define output matrixes\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # loop from the initial state to the second last state\n",
    "    current_state = planning_graph.task.initial_state\n",
    "    current_cost = len(plan_actions)\n",
    "    for i in range(0,len(plan_actions)-1):\n",
    "        X.append(generate_feature_vec(planning_graph, current_state, max_level))\n",
    "        y.append(current_cost)\n",
    "        current_action = find_operator(plan_actions[i], planning_graph.task.operators)\n",
    "        current_state = current_action.apply(current_state)\n",
    "        current_cost -=1\n",
    "        \n",
    "    y = np.c_[y, problem_num * np.ones(len(y))]\n",
    "    return np.asarray(X), np.asarray(y)\n",
    "\n",
    "def generate_problem_matrix(domain_file_path, problem_folder_path, log_folder_path, output_path, title):\n",
    "    \"\"\"\n",
    "    Generate the corresponding feature/label matrix from the given inputs\n",
    "    Stores in the format of \"title.npz\" in the output_path\n",
    "    Each npz file contain two attribute: \"feature\" and \"label\"\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    domain_file_path: the path to the domain.pddl\n",
    "    problem_folder_path: the path to the problem_folder containing all the task problem.pddl for generating vectors\n",
    "    plan_folder_path: the plan folder that contains all the log files corresponding to each problem task\n",
    "    output_path: the place to store the generated problem matrix\n",
    "    title: the name for the output npz file\n",
    "    \"\"\"\n",
    "    # get the training problem names and initialise parameters\n",
    "    problem_name_list = [f.split('.')[0] for f in os.listdir(problem_folder_path)]\n",
    "    X = None\n",
    "    Y = None\n",
    "    problem_index = 0\n",
    "    print(problem_name_list)\n",
    "    \n",
    "    # generate the final vectors in X, Y\n",
    "    for prob in problem_name_list:\n",
    "        problem_path = problem_folder_path + \"/\" + prob + \".pddl\"\n",
    "        plan_path = log_folder_path + \"/\" + prob + \"_1800.out\"\n",
    "        try:\n",
    "            temp_X, temp_Y = generate_training_data(domain_file_path, problem_path, plan_path, problem_index)\n",
    "            if X is None:\n",
    "                X = temp_X\n",
    "                Y = temp_Y\n",
    "            elif temp_X is not None:\n",
    "                X = np.vstack((X, temp_X))\n",
    "                Y = np.vstack((Y, temp_Y))\n",
    "            print(problem_path,X.shape, Y.shape)\n",
    "            problem_index += 1\n",
    "        except:\n",
    "            print(\"error occurs\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "    # save the final training vectors\n",
    "    np.savez(output_path+\"/\"+title+\".npz\", feature = X, label = Y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cdfd671c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12.  10.  68.  40.   0.   0.   6.   6.   0.   0.   0.  32.   4.  24.\n",
      "   0.   0.  24. 144.   0.  14.   0.  32.  40.  32.  66. 160. 187. 242.\n",
      "   9.  80.   5.   0.  86. 472.  20.  36.   5.  21.   0.]\n"
     ]
    }
   ],
   "source": [
    "rpl = RelaxedPlanningGraph(\"benchmarks/blocks/domain.pddl\",\"benchmarks/blocks/task07.pddl\")\n",
    "\n",
    "rtn = generate_feature_vec_relaxed(rpl, None, 999)\n",
    "\n",
    "# for a in list(graph.act.values()):\n",
    "#     print(a)\n",
    "\n",
    "print(rtn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7fdf3ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm, linear_model\n",
    "\n",
    "\n",
    "def transform_pairwise(X, y):\n",
    "    \"\"\"\n",
    "    Transforms data into pairs for convex relaxation of kendal rank correlation coef\n",
    "    In this method, all pairs are choosen, except for those that have the same target value or equal cost\n",
    "    Inputs\n",
    "    ----------\n",
    "    X : array, shape (n_samples, n_features)\n",
    "        The input feature vec of states from of several problems\n",
    "    y : array, shape (n_samples,) or (n_samples, 2)\n",
    "        The input cost vector. If it's a 2D array, the second column represents\n",
    "        the problem index\n",
    "    Returns\n",
    "    -------\n",
    "    X_trans : array, shape (k, n_feaures)\n",
    "        Difference between features of states (si - sj), only consider the state pair from the same problem\n",
    "    y_trans : array, shape (k,)\n",
    "        Output rank labels of values {-1, +1}, 1 represent si has potentially larger cost than sj (further away from goal)\n",
    "    \"\"\"\n",
    "    X_new = []\n",
    "    y_new = []\n",
    "    if y.ndim == 1:\n",
    "        y = np.c_[y, np.ones(y.shape[0])]\n",
    "    comb = itertools.combinations(range(X.shape[0]), 2)\n",
    "    for k, (i, j) in enumerate(comb):\n",
    "        if y[i, 0] == y[j, 0] or y[i, 1] != y[j, 1]:\n",
    "            # skip if they have the same cost or are from different problem group\n",
    "            continue\n",
    "        # otherwise, make the new pair-wise data\n",
    "        X_new.append(X[i] - X[j])\n",
    "        y_new.append(np.sign(y[i, 0] - y[j, 0])) # y = 1 if xi further away (larger cost), Vice Vesa\n",
    "        # randomly output some negative values for training purpose\n",
    "        if y_new[-1] != (-1) ** k:\n",
    "            y_new[-1] = - y_new[-1]\n",
    "            X_new[-1] = - X_new[-1]\n",
    "    return np.asarray(X_new), np.asarray(y_new)\n",
    "\n",
    "\n",
    "class RankSVM(svm.LinearSVC):\n",
    "    \"\"\"\n",
    "    Performs pairwise ranking svm with an underlying LinearSVC model\n",
    "    initialise with a C of regularization term\n",
    "    default using hinge loss\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, C = 1.0):\n",
    "        super(RankSVM, self).__init__()\n",
    "        self.C = C\n",
    "        self.loss = 'hinge'\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit a pairwise ranking model by first transfer it into pairwise than fitting\n",
    "        Inputs\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "        y : array, shape (n_samples,) or (n_samples, 2)\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        X_trans, y_trans = transform_pairwise(X, y)\n",
    "        super(RankSVM, self).fit(X_trans, y_trans)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict an ordering on X. For a list of n samples, this method\n",
    "        returns a list from 0 to n-1 with the relative order of the rows of X.\n",
    "        Inputs\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "        Returns\n",
    "        -------\n",
    "        rtn: array, shape (n_samples,)\n",
    "            Returns a list of integers representing the relative order of\n",
    "            the rows in X.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'coef_'):\n",
    "            return np.argsort(np.dot(X, self.coef_.T).flatten())\n",
    "        else:\n",
    "            raise ValueError(\"Must call fit() prior to predict()\")\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Returns the accuracy for the rank prediction, from 0-1\n",
    "        \"\"\"\n",
    "        X_trans, y_trans = transform_pairwise(X, y)\n",
    "        return np.mean(super(RankSVM, self).predict(X_trans) == y_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c07092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
