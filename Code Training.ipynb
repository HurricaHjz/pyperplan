{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8934fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "from scipy import stats\n",
    "import copy\n",
    "import os\n",
    "\n",
    "from pyperplan import planner as pl\n",
    "from pyperplan import search as sc\n",
    "from pyperplan.planner import (\n",
    "    find_domain,\n",
    "    HEURISTICS,\n",
    "    search_plan,\n",
    "    SEARCHES,\n",
    "    validate_solution,\n",
    "    write_solution,\n",
    ")\n",
    "from pyperplan.task import Operator, Task\n",
    "from pyperplan.heuristics.heuristic_base import Heuristic\n",
    "from pyperplan.search.a_star import greedy_best_first_search as gbfs\n",
    "from typing import Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b54a52",
   "metadata": {},
   "source": [
    "# Planning Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5951b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the planning graph\n",
    "class RelaxedGraph(object):\n",
    "    \n",
    "    def __init__(self): # initialise the Graph\n",
    "        self.num_of_levels: int = 0\n",
    "        self.act = {0: None}\n",
    "        self.prop = {}\n",
    "        self.fixed_point = False\n",
    "        \n",
    "            \n",
    "\n",
    "class RelaxedPlanningGraph(object):\n",
    "    \n",
    "    def __init__(self, domain_file: str, problem_file: str):\n",
    "        # initialise the relaxed planning graph\n",
    "        self.task = pl._ground(pl._parse(domain_file, problem_file))\n",
    "        self.graph = None\n",
    "        self.plan = None\n",
    "        self.hff = -1 # not yet generated\n",
    "        self.dom = domain_file\n",
    "        self.prob = problem_file\n",
    "        self.success = False # whether successfully generated or not\n",
    "        \n",
    "    def create(self, max_level, state = None):\n",
    "        # create the planning graph with a initial state specified\n",
    "        # return the level of relaxed graph generated, -1 if reached fixed point, -2 if reached max depth\n",
    "        self.graph = RelaxedGraph()\n",
    "        if state is not None:\n",
    "            self.graph.prop = {0: set(state)}\n",
    "        else:\n",
    "            self.graph.prop = {0: set(self.task.initial_state)}\n",
    "        goal_set = self.task.goals\n",
    " \n",
    "        for level in range(max_level+1):\n",
    "            current_props = self.graph.prop[level]\n",
    "            # if the goal has been satisfied\n",
    "            if Task.goal_reached(self.task, current_props):\n",
    "                self.success = True\n",
    "                return level\n",
    "            \n",
    "            # else expand the relaxed graph\n",
    "            self.graph.act[level+1] = set([op for op in self.task.operators if op.applicable(current_props)])\n",
    "            \n",
    "            next_props = current_props.copy()\n",
    "            for op in self.graph.act[level+1]:\n",
    "                next_props = next_props | op.add_effects\n",
    "            \n",
    "            if len(current_props) == len(next_props):\n",
    "                return -1 # reached fixed point before finding the goal\n",
    "            self.graph.prop[level+1] = next_props\n",
    "        \n",
    "        return -2 #reached max depth\n",
    "        \n",
    "    def hff_plan(self):\n",
    "        # generate a relaxed plan with hff \n",
    "        # first return error if graph not successfully generated\n",
    "        # return hff, -1 if failed\n",
    "        if self.graph is None:\n",
    "            print(\"Graph not yet generated\")\n",
    "            return -1 # graph not yet created\n",
    "        if not self.success:\n",
    "            print(\"Invalid graph\")\n",
    "            return -1 # graph does not reach goal state\n",
    "        \n",
    "        # otherwise start backtrace\n",
    "        # setup g_k\n",
    "        current_goal = set(self.task.goals.copy())\n",
    "        k = len(self.graph.act.keys())-1\n",
    "        self.plan = {}\n",
    "        for i in range(k, 0, -1):\n",
    "            act_set = set()\n",
    "            # select the minimum set of actions that r-satisfied current goal\n",
    "            for a in self.graph.act[i]:\n",
    "                for eff in a.add_effects:\n",
    "                    if eff in current_goal:\n",
    "                        current_goal.remove(eff)\n",
    "                        act_set.add(a)\n",
    "            # update the current goal to be the goals for previous layer\n",
    "            for a in act_set:\n",
    "                current_goal.update(a.preconditions)\n",
    "                \n",
    "            # update the final plan\n",
    "            self.plan[i] = list(act_set)\n",
    "\n",
    "        \n",
    "        if current_goal.issubset(self.graph.prop[0]):\n",
    "            count = 0\n",
    "            for layer in self.plan.values():\n",
    "                count+=len(layer)\n",
    "            self.hff = count\n",
    "            return self.hff\n",
    "        else:\n",
    "            print(\"something went wrong during planning\")\n",
    "            return -1\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c620cec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action:(pick-up b3), state: {'(on b1 b2)', '(on-table b2)', '(on b4 b1)', '(clear b4)', '(holding b3)'}\n",
      "action:(unstack b4 b1), state: {'(holding b4)', '(clear b3)', '(on b1 b2)', '(on-table b3)', '(on-table b2)', '(clear b1)'}\n",
      "\n",
      "action:(put-down b4), state: {'(clear b3)', '(on-table b4)', '(on b1 b2)', '(on-table b3)', '(on-table b2)', '(clear b1)', '(clear b4)', '(handempty)'}\n",
      "action:(stack b4 b3), state: {'(on b1 b2)', '(on-table b3)', '(on-table b2)', '(on b4 b3)', '(clear b1)', '(clear b4)', '(handempty)'}\n",
      "action:(stack b4 b1), state: {'(clear b3)', '(on b1 b2)', '(on-table b3)', '(on-table b2)', '(on b4 b1)', '(clear b4)', '(handempty)'}\n"
     ]
    }
   ],
   "source": [
    "rpl = RelaxedPlanningGraph(\"datasets/domain/blocks/domain.pddl\", \n",
    "                        \"datasets/domain/blocks/blocks/blocks4/task01.pddl\")\n",
    "plan = read_plan(\"datasets/domain/blocks/plans/blocks4-task01_1800.out\")\n",
    "rpl.create(999)\n",
    "\n",
    "graph = rpl.graph\n",
    "\n",
    "ini = graph.prop[0].copy()\n",
    "\n",
    "for a in rpl.task.operators:\n",
    "    if a.applicable(ini):\n",
    "        print(f'action:{a.name}, state:', a.apply(ini.copy()))\n",
    "\n",
    "op1 = find_operator(plan[0], rpl.task.operators)\n",
    "\n",
    "ini = op1.apply(ini)\n",
    "print()\n",
    "for a in rpl.task.operators:\n",
    "    if a.applicable(ini):\n",
    "        print(f'action:{a.name}, state:', a.apply(ini.copy()))\n",
    "    \n",
    "# graph.prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ecbcab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "fs = frozenset([6, 7, 8, 9])\n",
    "s = {1, 2, 3, 4, 5}\n",
    "\n",
    "y = {1,2,6}\n",
    "\n",
    "print(s - y) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f6d502",
   "metadata": {},
   "source": [
    "# Feature Vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d5d0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_vec_relaxed(planning_graph, state, max_level):\n",
    "    \"\"\"\n",
    "    Generate the feature vector followed by the paper from the input (problem, state) pair as described by the paper\n",
    "    Please notice that action and operator are referring to the same type Operator within this function\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    planning_graph: the relaxed planning graph DAG pi\n",
    "    state: the current state set of facts, it should never be the goal \n",
    "    max_level: the maximum layer allowed for ff algorithm to do forward expanding\n",
    "    \n",
    "    Outputs\n",
    "    ----------\n",
    "    feature_vec: a vector of length n + 2*n**2 + 3 representing the feature generated from the given (problem, state) pair\n",
    "                 the first n values are single action feature\n",
    "                 the second 2*n**2 are pairwise action feature\n",
    "                 the last 3 are original heuristic value, the number of layers in pi and the number of unsatisfied goals\n",
    "    \"\"\"\n",
    "    def get_name(op_name):\n",
    "        \"\"\"\n",
    "        transfer an operator name from format of \"(act_name v1 v2...)\" to act_name string\n",
    "        \"\"\"\n",
    "        return op_name.split(\" \")[0][1:]\n",
    "    \n",
    "    \n",
    "        \n",
    "    if planning_graph.task.goals <= state:\n",
    "        return feature_vec # if already the goal\n",
    "    \n",
    "    # get action schema and output list\n",
    "    act_schema = np.array(list(set([get_name(o.name) for o in planning_graph.task.operators]))) # store names of total action schema\n",
    "    n = len(act_schema)  # length of action schema\n",
    "    total_len = n+2*n**2+3\n",
    "    feature_vec = np.zeros(total_len) # return feature vec, first n is linear, second 2*n**2 is pairwise, last 3 is additional feature\n",
    "\n",
    "    \n",
    "    # create and get the graph\n",
    "    idx = planning_graph.create(max_level, state)\n",
    "    planning_graph.hff_plan()\n",
    "    graph = planning_graph.graph\n",
    "    act_layers = list(graph.act.values()) # list of layers generated, ith value is the list of actions connencting i-1 th states to ith states layer\n",
    "    # extract linear feature\n",
    "    #-------------------------------------\n",
    "    # ith value indicate the num of occurance for ith action of act_schema in the entire graph \n",
    "    counter = np.zeros(n)\n",
    "    for act_layer in act_layers:\n",
    "        if act_layer is not None:\n",
    "            for a in act_layer:\n",
    "                counter[act_schema == get_name(a.name)] += 1 \n",
    "    feature_vec[0:n] = counter\n",
    "    \n",
    "    # extract pair-wise feature\n",
    "    #-------------------------------------\n",
    "    # each pair a1, a2 is stored in n + [2*(n*a1+a2), 2*(n*a1+a2)+1]\n",
    "    # e.g. when a1 is 1, a2 is 3, n is 5, store in 5 + [2*(8),  2*(8)+1]\n",
    "    \n",
    "    def to_index(n, index_a1, index_a2, adder):\n",
    "        \"\"\"\n",
    "        return corresponding index in the position of the feature vector\n",
    "        adder is either 0 or 1\n",
    "        index_a1, index_a2 refer to move index in act_schema\n",
    "        \"\"\"\n",
    "        return n+2*(n*index_a1+index_a2)+adder\n",
    "    \n",
    "\n",
    "    def append_to_dict(a, pre, eff_pos):\n",
    "        \"\"\"\n",
    "        add action a into the dicitonary pre and eff_pos\n",
    "        \"\"\"\n",
    "        for p in a.preconditions:\n",
    "            current = pre.get(p)\n",
    "            if current is None:\n",
    "                current = [a]\n",
    "            else:\n",
    "                current.append(a)\n",
    "            pre[p] = current\n",
    "            \n",
    "        for p in a.add_effects:\n",
    "            current = eff_pos.get(p)\n",
    "            if current is None:\n",
    "                current = [a]\n",
    "            else:\n",
    "                current.append(a)\n",
    "            eff_pos[p] = current\n",
    "            \n",
    "            return pre, eff_pos\n",
    "\n",
    "\n",
    "    # define dictionary variables for comparison purpose\n",
    "    # each dictionary maps a fact(proposition) to a list of actions\n",
    "    pre = {}\n",
    "    eff_pos = {}\n",
    "    \n",
    "    # add pre and eff into the empty dictionary for the first layer\n",
    "    for a in act_layers[1]:\n",
    "        pre, eff_pos = append_to_dict(a, pre, eff_pos)\n",
    "   \n",
    "    # loop through second to last action layers\n",
    "    for i in range(2,len(act_layers)): \n",
    "        act_layer = act_layers[i]\n",
    "        \n",
    "        # update fecture vec for the entire layer based on all previously visited layers\n",
    "        for a2 in act_layer:\n",
    "            # count for num of occurances, use set to avoid multiple counts\n",
    "            s1 = set() # feature 1 where eff a1 and pre a2 has intersections\n",
    "            s2 = set() # feature 2 where pre a1 and eff a2 has intersections          \n",
    "            for p in a2.preconditions:\n",
    "                current = eff_pos.get(p)\n",
    "                if current is not None:\n",
    "                    for a1 in current:\n",
    "                        s1.add(a1) \n",
    "\n",
    "            for p in a2.add_effects:\n",
    "                current = pre.get(p)\n",
    "                if current is not None:\n",
    "                    for a1 in current:\n",
    "                        s2.add(a1)\n",
    "\n",
    "            # add index to feature_vec based on set generated:\n",
    "            index_a2 = int(np.where(get_name(a2.name) == act_schema)[0])\n",
    "            for a1 in s1:\n",
    "                # update feature 1 for pair (a1, a2)\n",
    "                index_a1 = int(np.where(get_name(a1.name) == act_schema)[0])\n",
    "                feature_vec[to_index(n, index_a1, index_a2,0)]+=1\n",
    "\n",
    "            for a1 in s2:\n",
    "                # update feature 2 for pair (a1, a2)\n",
    "                index_a1 = int(np.where(get_name(a1.name) == act_schema)[0])\n",
    "                feature_vec[to_index(n, index_a1, index_a2,1)]+=1\n",
    "\n",
    "        # update pre and eff_pos for the entire layer\n",
    "        for a2 in act_layer:\n",
    "            pre, eff_pos = append_to_dict(a2, pre, eff_pos)\n",
    "           \n",
    "    # extract final features\n",
    "    #-------------------------------------\n",
    "    # add heuristic value, number of layers and number of unsatisfied goals\n",
    "    # number of layers:\n",
    "    feature_vec[total_len - 3] = len(act_layers)\n",
    "    # heuristic value hFF: (number of total actions in the plan)\n",
    "    feature_vec[total_len - 2] = planning_graph.hff\n",
    "    # unsatisfied goal: (number of propositions within the initial state that's not in the goal)\n",
    "    ns_goals = 0\n",
    "    for fact in state:\n",
    "        if fact not in planning_graph.task.goals:\n",
    "            ns_goals += 1\n",
    "    feature_vec[total_len - 1] = ns_goals\n",
    "    \n",
    "\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa4039bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_operator(action : str, ops):\n",
    "    \"\"\"\n",
    "    find an operator from the planning graph's ground operator lists\n",
    "    \n",
    "    return: the action operator if found\n",
    "    \"\"\"\n",
    "    for op in ops:\n",
    "        if op.name == action:\n",
    "            return op\n",
    "    return None\n",
    "\n",
    "\n",
    "def read_plan(plan_file_path: str):\n",
    "    \"\"\"\n",
    "    read all the lines from a plan file directory, remove the last line containing cost\n",
    "    \n",
    "    return: a list containing the ground truth plan with length equal to total cost\n",
    "    \"\"\"\n",
    "    with open(plan_file_path, \"r\") as f:\n",
    "\n",
    "        # Read the lines of the file into a list of strings\n",
    "        lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    return lines[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc68364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(domain_file_path, task_file_path, plan_file_path, problem_num : int):\n",
    "    \"\"\"\n",
    "    generate the feature vector matrix X together with a cost vector y from the given input\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    domain_file_path: the input domain file\n",
    "    task_file_path: the input problem file\n",
    "    plan_file_path: the input log file that store the optimal plan\n",
    "    problem_num: the problem index for this domain\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    None, None if no plan can be found (plan has cost 0)\n",
    "    X : array, shape (plan_length-1, n_features)\n",
    "        The input feature vec of states from initial states all the way towards the second-last state (one state before goal state)\n",
    "    Y : array, shape (plan_length-1, 2)\n",
    "        The input cost vector. If it's a 2D array\n",
    "        The first column is the true cost pi optimal (assume unit cost)\n",
    "        The second column is the probelm_num representing the index of this problem\n",
    "    \n",
    "    \"\"\"\n",
    "    # generate plan and get max level\n",
    "    plan_actions = read_plan(plan_file_path)\n",
    "    if len(plan_actions) == 0:\n",
    "        return None, None\n",
    "    max_level = len(plan_actions)+2\n",
    "    \n",
    "    # generate relaxed planning graph\n",
    "    planning_graph = RelaxedPlanningGraph(domain_file_path, task_file_path)\n",
    "    \n",
    "    # define output matrixes\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # loop from the initial state to the second last state\n",
    "    current_state = planning_graph.task.initial_state\n",
    "    current_cost = len(plan_actions)\n",
    "    for i in range(0,len(plan_actions)-1):\n",
    "        X.append(generate_feature_vec_relaxed(planning_graph, current_state, max_level))\n",
    "        y.append(current_cost)\n",
    "        current_action = find_operator(plan_actions[i], planning_graph.task.operators)\n",
    "        current_state = current_action.apply(current_state)\n",
    "        current_cost -=1\n",
    "        \n",
    "    y = np.c_[y, problem_num * np.ones(len(y))]\n",
    "    return np.asarray(X), np.asarray(y)\n",
    "\n",
    "def generate_problem_matrix(domain_file_path, problem_folder_path, log_folder_path, output_path, title):\n",
    "    \"\"\"\n",
    "    Generate the corresponding feature/label matrix from the given inputs\n",
    "    Stores in the format of \"title.npz\" in the output_path\n",
    "    Each npz file contain two attribute: \"feature\" and \"label\"\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    domain_file_path: the path to the domain.pddl\n",
    "    problem_folder_path: the path to the problem_folder containing all the task problem.pddl for generating vectors\n",
    "    plan_folder_path: the plan folder that contains all the log files corresponding to each problem task\n",
    "    output_path: the place to store the generated problem matrix\n",
    "    title: the name for the output npz file\n",
    "    \"\"\"\n",
    "    # get the training problem names and initialise parameters\n",
    "    problem_name_list = [f.split('.')[0] for f in os.listdir(problem_folder_path)]\n",
    "    X = None\n",
    "    Y = None\n",
    "    problem_index = 0\n",
    "    \n",
    "    # generate the final vectors in X, Y\n",
    "    for prob in problem_name_list:\n",
    "        problem_path = problem_folder_path + \"/\" + prob + \".pddl\"\n",
    "        plan_path = log_folder_path + \"/\" + prob + \"_1800.out\"\n",
    "        temp_X, temp_Y = generate_training_data(domain_file_path, problem_path, plan_path, problem_index)\n",
    "        if X is None:\n",
    "            X = temp_X\n",
    "            Y = temp_Y\n",
    "        elif temp_X is not None:\n",
    "            X = np.vstack((X, temp_X))\n",
    "            Y = np.vstack((Y, temp_Y))\n",
    "        problem_index += 1\n",
    "       \n",
    "        \n",
    "        \n",
    "    # save the final training vectors\n",
    "    np.savez(output_path+\"/\"+title+\".npz\", feature = X, label = Y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b09e1d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = generate_training_data(\"datasets/domain/transport/domain.pddl\", \n",
    "                              \"datasets/domain/transport/train/instance-1.pddl\", \n",
    "                              \"datasets/domain/transport/plans/instance-1_1800.out\",\n",
    "                              0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef9c7ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.,  0.],\n",
       "       [12.,  0.],\n",
       "       [11.,  0.],\n",
       "       [10.,  0.],\n",
       "       [ 9.,  0.],\n",
       "       [ 8.,  0.],\n",
       "       [ 7.,  0.],\n",
       "       [ 6.,  0.],\n",
       "       [ 5.,  0.],\n",
       "       [ 4.,  0.],\n",
       "       [ 3.,  0.],\n",
       "       [ 2.,  0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28428429",
   "metadata": {},
   "source": [
    "# RankSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7fdf3ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def transform_pairwise(X, y):\n",
    "    \"\"\"\n",
    "    Transforms data into pairs for convex relaxation of kendal rank correlation coef\n",
    "    In this method, all pairs are choosen, except for those that have the same target value or equal cost\n",
    "    Inputs\n",
    "    ----------\n",
    "    X : array, shape (n_samples, n_features)\n",
    "        The input feature vec of states from of several problems\n",
    "    y : array, shape (n_samples,) or (n_samples, 2)\n",
    "        The input cost vector. If it's a 2D array, the second column represents\n",
    "        the problem index\n",
    "    Returns\n",
    "    -------\n",
    "    X_trans : array, shape (k, n_feaures)\n",
    "        Difference between features of states (si - sj), only consider the state pair from the same problem\n",
    "    y_trans : array, shape (k,)\n",
    "        Output rank labels of values {-1, +1}, 1 represent si has potentially larger cost than sj (further away from goal)\n",
    "    \"\"\"\n",
    "    X_new = []\n",
    "    y_new = []\n",
    "    if y.ndim == 1:\n",
    "        y = np.c_[y, np.ones(y.shape[0])]\n",
    "    comb = itertools.combinations(range(X.shape[0]), 2)\n",
    "    for k, (i, j) in enumerate(comb):\n",
    "        if y[i, 0] == y[j, 0] or y[i, 1] != y[j, 1]:\n",
    "            # skip if they have the same cost or are from different problem group\n",
    "            continue\n",
    "        # otherwise, make the new pair-wise data\n",
    "        X_new.append(X[i] - X[j])\n",
    "        y_new.append(np.sign(y[i, 0] - y[j, 0])) # y = 1 if xi further away (larger cost), Vice Vesa\n",
    "        # randomly output some negative values for training purpose\n",
    "        if y_new[-1] != (-1) ** k:\n",
    "            y_new[-1] = - y_new[-1]\n",
    "            X_new[-1] = - X_new[-1]\n",
    "    return np.asarray(X_new), np.asarray(y_new)\n",
    "\n",
    "\n",
    "class RankSVM(svm.LinearSVC):\n",
    "    \"\"\"\n",
    "    Performs pairwise ranking svm with an underlying LinearSVC model\n",
    "    initialise with a C of regularization term\n",
    "    default using hinge loss\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, C = 1.0):\n",
    "        super(RankSVM, self).__init__()\n",
    "        self.C = C\n",
    "        self.loss = 'hinge'\n",
    "        self.fit_intercept = False\n",
    "        self.max_iter = 9999\n",
    "#         self.scaler = StandardScaler()\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit a pairwise ranking model by first transfer it into pairwise than fitting\n",
    "        Inputs\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "        y : array, shape (n_samples,) or (n_samples, 2)\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        X_trans, y_trans = transform_pairwise(X, y)\n",
    "        super(RankSVM, self).fit(X_trans, y_trans)\n",
    "#         X_scaled = self.scaler.fit_transform(X_trans)\n",
    "#         super(RankSVM, self).fit(X_scaled, y_trans)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict an ordering on X. For a list of n samples, this method\n",
    "        returns a list from 0 to n-1 with the relative order of the rows of X.\n",
    "        Inputs\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "        Returns\n",
    "        -------\n",
    "        rtn: array, shape (n_samples,)\n",
    "            Returns a list of integers representing the relative order of\n",
    "            the rows in X.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'coef_'):\n",
    "#             return np.argsort(np.dot(self.scaler.transform(X), self.coef_.T).flatten())\n",
    "            return np.argsort(np.dot(X, self.coef_.T).flatten())\n",
    "        else:\n",
    "            raise ValueError(\"Must call fit() prior to predict()\")\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Returns the accuracy for the rank prediction, from 0-1\n",
    "        \"\"\"\n",
    "        X_trans, y_trans = transform_pairwise(X, y)\n",
    "        return np.mean(super(RankSVM, self).predict(X_trans) == y_trans)\n",
    "    \n",
    "    def h_val(self, x):\n",
    "        \"\"\"\n",
    "        return pseduo heuristic for search\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'coef_'):\n",
    "            x_r = x.reshape(1,-1)\n",
    "#             return np.dot(self.scaler.transform(x_r), self.coef_.T)\n",
    "            return np.dot(x_r, self.coef_.T)\n",
    "        else:\n",
    "            raise ValueError(\"Must call fit() prior to predict()\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473ae069",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "70c07092",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankHeuristic(Heuristic):\n",
    "    \"\"\"\n",
    "    Implement the heuristic using the trained RankSVM's coef for dot product\n",
    "    \n",
    "    Inadmissible, directly reflect the rank\n",
    "    \n",
    "    Default scale value is 10000\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, svm : RankSVM, planning_graph, scale_val = 10000):\n",
    "        super().__init__()\n",
    "        self.svm = svm\n",
    "        self.planning_graph = planning_graph\n",
    "        self.scale = scale_val\n",
    "        self.expand_nodes = 0\n",
    "        \n",
    "    def __call__(self, node):\n",
    "        self.expand_nodes += 1\n",
    "        if (self.planning_graph.task.goals <= node.state):\n",
    "            print(\"reached goal state\")\n",
    "            return 0\n",
    "        vec = generate_feature_vec_relaxed(self.planning_graph, node.state, 9999999999)\n",
    "        h = round(self.svm.h_val(vec).item()*self.scale)\n",
    "#         print(f'heristic values:{h}')\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c69102e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "83e21aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_optimal(domain_path, test_folder_path, log_folder_path, svm):\n",
    "    \"\"\"\n",
    "    return: the percentage of problems that get solved and returned the optimal path\n",
    "    if not optimal, print the difference of length as output\n",
    "    \"\"\"\n",
    "    \n",
    "    problem_name_list = [f.split('.')[0] for f in os.listdir(test_folder_path)]\n",
    "    print(problem_name_list)\n",
    "    correct_optimal = 0\n",
    "    for prob in problem_name_list:\n",
    "        # retrieve the problem and plan file path\n",
    "        problem_path = test_folder_path + \"/\" + prob + \".pddl\"\n",
    "        plan_path = log_folder_path + \"/\" + prob + \"_1800.out\"\n",
    "\n",
    "        \n",
    "        # generate test plan and heuristic instance\n",
    "        test_plan = RelaxedPlanningGraph(domain_path, problem_path)\n",
    "\n",
    "        rank_h = RankHeuristic(svm, test_plan)\n",
    "        \n",
    "        # get solution using gbfs\n",
    "        sol = gbfs(test_plan.task, rank_h)\n",
    "        print(f'Nodes expanded:{rank_h.expand_nodes}')\n",
    "        \n",
    "        my_len = len(sol)\n",
    "        true_len = len(read_plan(plan_path))\n",
    "        print(f'For problem {prob}')\n",
    "        if my_len != true_len:\n",
    "            print(f'my plan length: {my_len}, optimal plan length: {true_len}')\n",
    "        else:\n",
    "            print(f'get true optimal length {my_len}')\n",
    "            correct_optimal += 1\n",
    "            \n",
    "    return correct_optimal / len(problem_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7a67d4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94, 39) (94, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Apps\\Anaconda\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-49 {color: black;background-color: white;}#sk-container-id-49 pre{padding: 0;}#sk-container-id-49 div.sk-toggleable {background-color: white;}#sk-container-id-49 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-49 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-49 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-49 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-49 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-49 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-49 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-49 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-49 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-49 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-49 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-49 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-49 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-49 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-49 div.sk-item {position: relative;z-index: 1;}#sk-container-id-49 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-49 div.sk-item::before, #sk-container-id-49 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-49 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-49 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-49 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-49 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-49 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-49 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-49 div.sk-label-container {text-align: center;}#sk-container-id-49 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-49 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-49\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RankSVM(C=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" checked><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RankSVM</label><div class=\"sk-toggleable__content\"><pre>RankSVM(C=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RankSVM(C=0.1)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train blocks\n",
    "generate_problem_matrix(\"datasets/domain/blocks/domain.pddl\", \n",
    "                        \"datasets/domain/blocks/train\", \n",
    "                        \"datasets/domain/blocks/plans\", \n",
    "                        \"datasets/results\", \n",
    "                        \"blocks-train\")\n",
    "svm_block = RankSVM(C = 0.1)\n",
    "results = np.load(\"datasets/results/blocks-train.npz\")\n",
    "X = results['feature']\n",
    "Y = results['label']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "svm_block.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "503c4e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached goal state\n",
      "Nodes expanded:4\n",
      "plan length2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Op (unstack b3 b2)>, <Op (put-down b3)>]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test blocks 1\n",
    "test_plan = RelaxedPlanningGraph(\"datasets/domain/blocks/domain.pddl\", \n",
    "                                 \"datasets/domain/blocks/blocks/blocks3/task01.pddl\")\n",
    "\n",
    "rank_h = RankHeuristic(svm_block, test_plan)\n",
    "\n",
    "rtn = gbfs(test_plan.task, rank_h)\n",
    "print(f'Nodes expanded:{rank_h.expand_nodes}')\n",
    "print(f'plan length{len(rtn)}')\n",
    "rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0f86234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blocks3-task04', 'blocks3-task05', 'blocks3-task06', 'blocks3-task07', 'blocks3-task08', 'blocks3-task09', 'blocks3-task10', 'blocks4-task05', 'blocks4-task06', 'blocks4-task07', 'blocks4-task08', 'blocks4-task09', 'blocks4-task10', 'blocks5-task04', 'blocks5-task05', 'blocks5-task06', 'blocks5-task07', 'blocks5-task08', 'blocks5-task09', 'blocks5-task10', 'blocks6-task06', 'blocks6-task07', 'blocks6-task08', 'blocks6-task09', 'blocks6-task10', 'blocks7-task02', 'blocks7-task03', 'blocks7-task04', 'blocks7-task05', 'blocks8-task02', 'blocks8-task03', 'blocks8-task04']\n",
      "reached goal state\n",
      "Nodes expanded:15\n",
      "For problem blocks3-task04\n",
      "get true optimal length 6\n",
      "reached goal state\n",
      "Nodes expanded:15\n",
      "For problem blocks3-task05\n",
      "get true optimal length 6\n",
      "reached goal state\n",
      "Nodes expanded:12\n",
      "For problem blocks3-task06\n",
      "get true optimal length 4\n",
      "reached goal state\n",
      "Nodes expanded:14\n",
      "For problem blocks3-task07\n",
      "get true optimal length 4\n",
      "reached goal state\n",
      "Nodes expanded:23\n",
      "For problem blocks3-task08\n",
      "get true optimal length 6\n",
      "reached goal state\n",
      "Nodes expanded:26\n",
      "For problem blocks3-task09\n",
      "get true optimal length 8\n",
      "reached goal state\n",
      "Nodes expanded:18\n",
      "For problem blocks3-task10\n",
      "get true optimal length 4\n",
      "reached goal state\n",
      "Nodes expanded:38\n",
      "For problem blocks4-task05\n",
      "get true optimal length 10\n",
      "reached goal state\n",
      "Nodes expanded:74\n",
      "For problem blocks4-task06\n",
      "get true optimal length 12\n",
      "reached goal state\n",
      "Nodes expanded:40\n",
      "For problem blocks4-task07\n",
      "get true optimal length 8\n",
      "reached goal state\n",
      "Nodes expanded:42\n",
      "For problem blocks4-task08\n",
      "my plan length: 14, optimal plan length: 12\n",
      "reached goal state\n",
      "Nodes expanded:16\n",
      "For problem blocks4-task09\n",
      "get true optimal length 4\n",
      "reached goal state\n",
      "Nodes expanded:21\n",
      "For problem blocks4-task10\n",
      "get true optimal length 6\n",
      "reached goal state\n",
      "Nodes expanded:19\n",
      "For problem blocks5-task04\n",
      "get true optimal length 6\n",
      "reached goal state\n",
      "Nodes expanded:48\n",
      "For problem blocks5-task05\n",
      "my plan length: 14, optimal plan length: 10\n",
      "reached goal state\n",
      "Nodes expanded:40\n",
      "For problem blocks5-task06\n",
      "get true optimal length 10\n",
      "reached goal state\n",
      "Nodes expanded:54\n",
      "For problem blocks5-task07\n",
      "my plan length: 12, optimal plan length: 10\n",
      "reached goal state\n",
      "Nodes expanded:38\n",
      "For problem blocks5-task08\n",
      "get true optimal length 10\n",
      "reached goal state\n",
      "Nodes expanded:52\n",
      "For problem blocks5-task09\n",
      "get true optimal length 12\n",
      "reached goal state\n",
      "Nodes expanded:52\n",
      "For problem blocks5-task10\n",
      "my plan length: 14, optimal plan length: 10\n",
      "reached goal state\n",
      "Nodes expanded:147\n",
      "For problem blocks6-task06\n",
      "my plan length: 32, optimal plan length: 14\n",
      "reached goal state\n",
      "Nodes expanded:181\n",
      "For problem blocks6-task07\n",
      "my plan length: 16, optimal plan length: 12\n",
      "reached goal state\n",
      "Nodes expanded:72\n",
      "For problem blocks6-task08\n",
      "my plan length: 20, optimal plan length: 14\n",
      "reached goal state\n",
      "Nodes expanded:72\n",
      "For problem blocks6-task09\n",
      "get true optimal length 14\n",
      "reached goal state\n",
      "Nodes expanded:177\n",
      "For problem blocks6-task10\n",
      "my plan length: 18, optimal plan length: 10\n",
      "reached goal state\n",
      "Nodes expanded:63\n",
      "For problem blocks7-task02\n",
      "my plan length: 8, optimal plan length: 6\n",
      "reached goal state\n",
      "Nodes expanded:382\n",
      "For problem blocks7-task03\n",
      "my plan length: 38, optimal plan length: 18\n",
      "reached goal state\n",
      "Nodes expanded:185\n",
      "For problem blocks7-task04\n",
      "my plan length: 32, optimal plan length: 16\n",
      "reached goal state\n",
      "Nodes expanded:851\n",
      "For problem blocks7-task05\n",
      "my plan length: 38, optimal plan length: 14\n",
      "reached goal state\n",
      "Nodes expanded:531\n",
      "For problem blocks8-task02\n",
      "my plan length: 66, optimal plan length: 20\n",
      "reached goal state\n",
      "Nodes expanded:96\n",
      "For problem blocks8-task03\n",
      "my plan length: 16, optimal plan length: 12\n",
      "reached goal state\n",
      "Nodes expanded:623\n",
      "For problem blocks8-task04\n",
      "my plan length: 46, optimal plan length: 18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.53125"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test blocks 2\n",
    "test_optimal(\"datasets/domain/blocks/domain.pddl\",\n",
    "            \"datasets/domain/blocks/test-svm\",\n",
    "            \"datasets/domain/blocks/plans\",\n",
    "            svm_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d40377ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 24) (45, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Apps\\Anaconda\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-37 {color: black;background-color: white;}#sk-container-id-37 pre{padding: 0;}#sk-container-id-37 div.sk-toggleable {background-color: white;}#sk-container-id-37 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-37 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-37 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-37 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-37 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-37 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-37 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-37 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-37 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-37 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-37 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-37 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-37 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-37 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-37 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-37 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-37 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-37 div.sk-item {position: relative;z-index: 1;}#sk-container-id-37 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-37 div.sk-item::before, #sk-container-id-37 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-37 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-37 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-37 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-37 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-37 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-37 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-37 div.sk-label-container {text-align: center;}#sk-container-id-37 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-37 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-37\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RankSVM(C=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" checked><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RankSVM</label><div class=\"sk-toggleable__content\"><pre>RankSVM(C=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RankSVM(C=0.1)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train ferry\n",
    "generate_problem_matrix(\"datasets/domain/ferry/domain.pddl\", \n",
    "                        \"datasets/domain/ferry/train\", \n",
    "                        \"datasets/domain/ferry/plans\", \n",
    "                        \"datasets/results\", \n",
    "                        \"ferry-train\")\n",
    "\n",
    "svm_ferry = RankSVM(C = 0.1)\n",
    "results = np.load(\"datasets/results/ferry-train.npz\")\n",
    "X = results['feature']\n",
    "Y = results['label']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "svm_ferry.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9189ef78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached goal state\n",
      "Nodes expanded:376\n",
      "plan length21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Op (board c14 l1)>,\n",
       " <Op (sail l1 l0)>,\n",
       " <Op (debark c14 l0)>,\n",
       " <Op (board c5 l0)>,\n",
       " <Op (sail l0 l1)>,\n",
       " <Op (debark c5 l1)>,\n",
       " <Op (board c6 l1)>,\n",
       " <Op (sail l1 l0)>,\n",
       " <Op (debark c6 l0)>,\n",
       " <Op (board c4 l0)>,\n",
       " <Op (sail l0 l1)>,\n",
       " <Op (debark c4 l1)>,\n",
       " <Op (board c3 l1)>,\n",
       " <Op (sail l1 l0)>,\n",
       " <Op (debark c3 l0)>,\n",
       " <Op (board c11 l0)>,\n",
       " <Op (sail l0 l1)>,\n",
       " <Op (debark c11 l1)>,\n",
       " <Op (board c1 l1)>,\n",
       " <Op (sail l1 l0)>,\n",
       " <Op (debark c1 l0)>]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test ferry 1\n",
    "test_plan = RelaxedPlanningGraph(\"datasets/domain/ferry/domain.pddl\", \n",
    "                                 \"datasets/domain/ferry/test/ferry-l2-c15.pddl\")\n",
    "\n",
    "rank_h = RankHeuristic(svm_ferry, test_plan)\n",
    "\n",
    "rtn = gbfs(test_plan.task, rank_h)\n",
    "print(f'Nodes expanded:{rank_h.expand_nodes}')\n",
    "print(f'plan length{len(rtn)}')\n",
    "rtn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "71358a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ferry-l2-c10', 'ferry-l2-c15', 'ferry-l2-c20', 'ferry-l2-c5', 'ferry-l3-c10', 'ferry-l3-c15', 'ferry-l3-c5', 'ferry-l4-c10', 'ferry-l4-c15', 'ferry-l4-c5', 'ferry-l5-c10', 'ferry-l5-c15', 'ferry-l5-c5']\n",
      "reached goal state\n",
      "Nodes expanded:38\n",
      "For problem ferry-l2-c10\n",
      "get true optimal length 10\n",
      "reached goal state\n",
      "Nodes expanded:376\n",
      "For problem ferry-l2-c15\n",
      "get true optimal length 21\n",
      "reached goal state\n",
      "Nodes expanded:1147\n",
      "For problem ferry-l2-c20\n",
      "my plan length: 28, optimal plan length: 25\n",
      "reached goal state\n",
      "Nodes expanded:17\n",
      "For problem ferry-l2-c5\n",
      "get true optimal length 6\n",
      "reached goal state\n",
      "Nodes expanded:118\n",
      "For problem ferry-l3-c10\n",
      "my plan length: 18, optimal plan length: 14\n",
      "reached goal state\n",
      "Nodes expanded:6649\n",
      "For problem ferry-l3-c15\n",
      "my plan length: 79, optimal plan length: 35\n",
      "reached goal state\n",
      "Nodes expanded:81\n",
      "For problem ferry-l3-c5\n",
      "my plan length: 17, optimal plan length: 15\n",
      "reached goal state\n",
      "Nodes expanded:524\n",
      "For problem ferry-l4-c10\n",
      "my plan length: 22, optimal plan length: 21\n",
      "reached goal state\n",
      "Nodes expanded:899\n",
      "For problem ferry-l4-c15\n",
      "my plan length: 48, optimal plan length: 40\n",
      "reached goal state\n",
      "Nodes expanded:100\n",
      "For problem ferry-l4-c5\n",
      "get true optimal length 14\n",
      "reached goal state\n",
      "Nodes expanded:477\n",
      "For problem ferry-l5-c10\n",
      "my plan length: 29, optimal plan length: 26\n",
      "reached goal state\n",
      "Nodes expanded:5847\n",
      "For problem ferry-l5-c15\n",
      "my plan length: 58, optimal plan length: 39\n",
      "reached goal state\n",
      "Nodes expanded:130\n",
      "For problem ferry-l5-c5\n",
      "get true optimal length 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38461538461538464"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test ferry 2\n",
    "test_optimal(\"datasets/domain/ferry/domain.pddl\",\n",
    "            \"datasets/domain/ferry/test-svm\",\n",
    "            \"datasets/domain/ferry/plans\",\n",
    "            svm_ferry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "62439d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 24) (108, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Apps\\Anaconda\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-39 {color: black;background-color: white;}#sk-container-id-39 pre{padding: 0;}#sk-container-id-39 div.sk-toggleable {background-color: white;}#sk-container-id-39 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-39 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-39 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-39 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-39 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-39 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-39 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-39 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-39 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-39 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-39 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-39 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-39 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-39 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-39 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-39 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-39 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-39 div.sk-item {position: relative;z-index: 1;}#sk-container-id-39 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-39 div.sk-item::before, #sk-container-id-39 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-39 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-39 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-39 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-39 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-39 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-39 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-39 div.sk-label-container {text-align: center;}#sk-container-id-39 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-39 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-39\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RankSVM(C=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" checked><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RankSVM</label><div class=\"sk-toggleable__content\"><pre>RankSVM(C=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RankSVM(C=0.1)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train gripper\n",
    "generate_problem_matrix(\"datasets/domain/gripper/domain.pddl\", \n",
    "                        \"datasets/domain/gripper/train\", \n",
    "                        \"datasets/domain/gripper/plans\", \n",
    "                        \"datasets/results\", \n",
    "                        \"gripper-train\")\n",
    "svm_gripper = RankSVM(C = 0.1)\n",
    "results = np.load(\"datasets/results/gripper-train.npz\")\n",
    "X = results['feature']\n",
    "Y = results['label']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "svm_gripper.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b7b887c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached goal state\n",
      "Nodes expanded:48\n",
      "plan length11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Op (pick ball2 rooma left)>,\n",
       " <Op (pick ball3 rooma right)>,\n",
       " <Op (move rooma roomb)>,\n",
       " <Op (drop ball2 roomb left)>,\n",
       " <Op (drop ball3 roomb right)>,\n",
       " <Op (move roomb rooma)>,\n",
       " <Op (pick ball4 rooma left)>,\n",
       " <Op (pick ball1 rooma right)>,\n",
       " <Op (move rooma roomb)>,\n",
       " <Op (drop ball4 roomb left)>,\n",
       " <Op (drop ball1 roomb right)>]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test gripper 1\n",
    "test_plan = RelaxedPlanningGraph(\"datasets/domain/gripper/domain.pddl\", \n",
    "                                 \"datasets/domain/gripper/test/gripper-n4.pddl\")\n",
    "\n",
    "rank_h = RankHeuristic(svm_gripper, test_plan)\n",
    "\n",
    "rtn = gbfs(test_plan.task, rank_h)\n",
    "print(f'Nodes expanded:{rank_h.expand_nodes}')\n",
    "print(f'plan length{len(rtn)}')\n",
    "rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "532090cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gripper-n13', 'gripper-n14', 'gripper-n15', 'gripper-n16', 'gripper-n17', 'gripper-n4', 'gripper-n5', 'gripper-n6', 'gripper-n7', 'gripper-n8', 'gripper-n9']\n",
      "reached goal state\n",
      "Nodes expanded:377\n",
      "For problem gripper-n13\n",
      "get true optimal length 39\n",
      "reached goal state\n",
      "Nodes expanded:396\n",
      "For problem gripper-n14\n",
      "get true optimal length 41\n",
      "reached goal state\n",
      "Nodes expanded:476\n",
      "For problem gripper-n15\n",
      "get true optimal length 45\n",
      "reached goal state\n",
      "Nodes expanded:516\n",
      "For problem gripper-n16\n",
      "get true optimal length 47\n",
      "reached goal state\n",
      "Nodes expanded:608\n",
      "For problem gripper-n17\n",
      "get true optimal length 51\n",
      "reached goal state\n",
      "Nodes expanded:48\n",
      "For problem gripper-n4\n",
      "get true optimal length 11\n",
      "reached goal state\n",
      "Nodes expanded:77\n",
      "For problem gripper-n5\n",
      "get true optimal length 15\n",
      "reached goal state\n",
      "Nodes expanded:96\n",
      "For problem gripper-n6\n",
      "get true optimal length 17\n",
      "reached goal state\n",
      "Nodes expanded:128\n",
      "For problem gripper-n7\n",
      "get true optimal length 21\n",
      "reached goal state\n",
      "Nodes expanded:150\n",
      "For problem gripper-n8\n",
      "get true optimal length 23\n",
      "reached goal state\n",
      "Nodes expanded:200\n",
      "For problem gripper-n9\n",
      "get true optimal length 27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test gripper 2\n",
    "test_optimal(\"datasets/domain/gripper/domain.pddl\",\n",
    "            \"datasets/domain/gripper/test-svm\",\n",
    "            \"datasets/domain/gripper/plans\",\n",
    "            svm_gripper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ddbce782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 58) (120, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Apps\\Anaconda\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-44 {color: black;background-color: white;}#sk-container-id-44 pre{padding: 0;}#sk-container-id-44 div.sk-toggleable {background-color: white;}#sk-container-id-44 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-44 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-44 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-44 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-44 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-44 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-44 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-44 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-44 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-44 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-44 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-44 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-44 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-44 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-44 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-44 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-44 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-44 div.sk-item {position: relative;z-index: 1;}#sk-container-id-44 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-44 div.sk-item::before, #sk-container-id-44 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-44 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-44 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-44 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-44 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-44 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-44 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-44 div.sk-label-container {text-align: center;}#sk-container-id-44 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-44 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-44\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RankSVM(C=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" checked><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RankSVM</label><div class=\"sk-toggleable__content\"><pre>RankSVM(C=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RankSVM(C=0.1)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train zeno\n",
    "generate_problem_matrix(\"datasets/domain/zenotravel/domain.pddl\", \n",
    "                        \"datasets/domain/zenotravel/train\", \n",
    "                        \"datasets/domain/zenotravel/plans\", \n",
    "                        \"datasets/results\", \n",
    "                        \"zenotravel-train\")\n",
    "svm_zeno = RankSVM(C = 0.1)\n",
    "results = np.load(\"datasets/results/zenotravel-train.npz\")\n",
    "X = results['feature']\n",
    "Y = results['label']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "svm_zeno.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fa5abafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached goal state\n",
      "Nodes expanded:56\n",
      "plan length6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Op (refuel plane2 city1 fl0 fl1)>,\n",
       " <Op (board person2 plane2 city1)>,\n",
       " <Op (refuel plane2 city1 fl1 fl2)>,\n",
       " <Op (fly plane2 city1 city0 fl2 fl1)>,\n",
       " <Op (debark person2 plane2 city0)>,\n",
       " <Op (fly plane2 city0 city1 fl1 fl0)>]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test zeno 1\n",
    "test_plan = RelaxedPlanningGraph(\"datasets/domain/zenotravel/domain.pddl\", \n",
    "                                 \"datasets/domain/zenotravel/test/zenotravel-cities2-planes2-people5-1564.pddl\")\n",
    "\n",
    "rank_h = RankHeuristic(svm_zeno, test_plan)\n",
    "\n",
    "rtn = gbfs(test_plan.task, rank_h)\n",
    "print(f'Nodes expanded:{rank_h.expand_nodes}')\n",
    "print(f'plan length{len(rtn)}')\n",
    "rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9ea9209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zenotravel-cities2-planes3-people6-6510', 'zenotravel-cities2-planes3-people7-3468', 'zenotravel-cities2-planes4-people4-2248', 'zenotravel-cities2-planes4-people4-6874', 'zenotravel-cities2-planes4-people7-6599', 'zenotravel-cities2-planes5-people3-9854', 'zenotravel-cities3-planes2-people4-6913', 'zenotravel-cities3-planes2-people7-1956', 'zenotravel-cities3-planes3-people4-2981', 'zenotravel-cities4-planes4-people6-1235', 'zenotravel-cities4-planes4-people7-4853', 'zenotravel-cities4-planes5-people3-3894']\n",
      "reached goal state\n",
      "Nodes expanded:1191\n",
      "For problem zenotravel-cities2-planes3-people6-6510\n",
      "my plan length: 14, optimal plan length: 10\n",
      "reached goal state\n",
      "Nodes expanded:23566\n",
      "For problem zenotravel-cities2-planes3-people7-3468\n",
      "my plan length: 23, optimal plan length: 16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[179], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# test zeno 2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_optimal(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/domain/zenotravel/domain.pddl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/domain/zenotravel/test-svm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/domain/zenotravel/plans\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m             svm_zeno)\n",
      "Cell \u001b[1;32mIn[142], line 22\u001b[0m, in \u001b[0;36mtest_optimal\u001b[1;34m(domain_path, test_folder_path, log_folder_path, svm)\u001b[0m\n\u001b[0;32m     19\u001b[0m rank_h \u001b[38;5;241m=\u001b[39m RankHeuristic(svm, test_plan)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# get solution using gbfs\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m sol \u001b[38;5;241m=\u001b[39m gbfs(test_plan\u001b[38;5;241m.\u001b[39mtask, rank_h)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNodes expanded:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrank_h\u001b[38;5;241m.\u001b[39mexpand_nodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m my_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sol)\n",
      "File \u001b[1;32mE:\\@uni_life\\@COMP3770\\@project\\pyperplan\\pyperplan\\search\\a_star.py:94\u001b[0m, in \u001b[0;36mgreedy_best_first_search\u001b[1;34m(task, heuristic, use_relaxed_plan)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgreedy_best_first_search\u001b[39m(task, heuristic, use_relaxed_plan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03m    Searches for a plan in the given task using greedy best first search.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m                     from a search node to reach the goal.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m astar_search(\n\u001b[0;32m     95\u001b[0m         task, heuristic, ordered_node_greedy_best_first, use_relaxed_plan\n\u001b[0;32m     96\u001b[0m     )\n",
      "File \u001b[1;32mE:\\@uni_life\\@COMP3770\\@project\\pyperplan\\pyperplan\\search\\a_star.py:180\u001b[0m, in \u001b[0;36mastar_search\u001b[1;34m(task, heuristic, make_open_entry, use_relaxed_plan)\u001b[0m\n\u001b[0;32m    177\u001b[0m         logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeeping operator \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m op\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    179\u001b[0m succ_node \u001b[38;5;241m=\u001b[39m searchspace\u001b[38;5;241m.\u001b[39mmake_child_node(pop_node, op, succ_state)\n\u001b[1;32m--> 180\u001b[0m h \u001b[38;5;241m=\u001b[39m heuristic(succ_node)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m h \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;66;03m# don't bother with states that can't reach the goal anyway\u001b[39;00m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[172], line 22\u001b[0m, in \u001b[0;36mRankHeuristic.__call__\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreached goal state\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 22\u001b[0m         vec \u001b[38;5;241m=\u001b[39m generate_feature_vec_relaxed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplanning_graph, node\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;241m9999999999\u001b[39m)\n\u001b[0;32m     23\u001b[0m         h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvm\u001b[38;5;241m.\u001b[39mh_val(vec)\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#         print(f'heristic values:{h}')\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[43], line 129\u001b[0m, in \u001b[0;36mgenerate_feature_vec_relaxed\u001b[1;34m(planning_graph, state, max_level)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a1 \u001b[38;5;129;01min\u001b[39;00m s2:\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;66;03m# update feature 2 for pair (a1, a2)\u001b[39;00m\n\u001b[0;32m    128\u001b[0m         index_a1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mwhere(get_name(a1\u001b[38;5;241m.\u001b[39mname) \u001b[38;5;241m==\u001b[39m act_schema)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 129\u001b[0m         feature_vec[to_index(n, index_a1, index_a2,\u001b[38;5;241m1\u001b[39m)]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# update pre and eff_pos for the entire layer\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a2 \u001b[38;5;129;01min\u001b[39;00m act_layer:\n",
      "Cell \u001b[1;32mIn[43], line 57\u001b[0m, in \u001b[0;36mgenerate_feature_vec_relaxed.<locals>.to_index\u001b[1;34m(n, index_a1, index_a2, adder)\u001b[0m\n\u001b[0;32m     50\u001b[0m feature_vec[\u001b[38;5;241m0\u001b[39m:n] \u001b[38;5;241m=\u001b[39m counter\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# extract pair-wise feature\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m#-------------------------------------\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# each pair a1, a2 is stored in n + [2*(n*a1+a2), 2*(n*a1+a2)+1]\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# e.g. when a1 is 1, a2 is 3, n is 5, store in 5 + [2*(8),  2*(8)+1]\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_index\u001b[39m(n, index_a1, index_a2, adder):\n\u001b[0;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m    return corresponding index in the position of the feature vector\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    adder is either 0 or 1\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    index_a1, index_a2 refer to move index in act_schema\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m n\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m(n\u001b[38;5;241m*\u001b[39mindex_a1\u001b[38;5;241m+\u001b[39mindex_a2)\u001b[38;5;241m+\u001b[39madder\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test zeno 2\n",
    "test_optimal(\"datasets/domain/zenotravel/domain.pddl\",\n",
    "            \"datasets/domain/zenotravel/test-svm\",\n",
    "            \"datasets/domain/zenotravel/plans\",\n",
    "            svm_zeno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b258b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
